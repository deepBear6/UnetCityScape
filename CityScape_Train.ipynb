{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import Unet\n",
    "import GetData\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import time\n",
    "from random import randint\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.get_device_name(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 224\n",
    "width = 224\n",
    "tfms = transforms.Compose([\n",
    "    transforms.Resize((height, width), interpolation=Image.NEAREST)])\n",
    "\n",
    "trainset = GetData.SegmentationDataset(image_dir=\"images/leftImg8bit/train\", \n",
    "                                      label_dir=\"labels_class/train\",\n",
    "                                      transform=tfms)\n",
    "trainloader = DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = GetData.SegmentationDataset(image_dir=\"images/leftImg8bit/val\", \n",
    "                                      label_dir=\"labels_class/val\",\n",
    "                                      transform=tfms)\n",
    "testloader = DataLoader(testset, batch_size=16, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, testloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(testloader):\n",
    "            image, inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs) \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            \n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "    img = image[0].cpu().data.numpy().reshape(height, width, 3)\n",
    "    label = labels[0].cpu().data.numpy().reshape(height, width)\n",
    "    preds = predicted[0].cpu().data.numpy().reshape(height, width)\n",
    "    concat_labels = np.concatenate([label, preds], axis=1)\n",
    "    ax[0].imshow(img.astype(np.uint8))\n",
    "    ax[1].imshow(concat_labels)\n",
    "    plt.show()\n",
    "    test_loss = running_loss/len(testloader)\n",
    "    print(f\"Test loss: {test_loss:.4f}\")\n",
    "    iou(preds, label)\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = {\n",
    "    0:\"void\",\n",
    "    1:\"flat\",\n",
    "    2:\"construction\",\n",
    "    3:\"object\",\n",
    "    4:\"nature\",\n",
    "    5:\"sky\",\n",
    "    6:\"human\",\n",
    "    7:\"vehicle\"\n",
    "}\n",
    "def iou(prediction, target):\n",
    "    mean = []\n",
    "    for i in range(8):\n",
    "        prediction_c = prediction==i\n",
    "        target_c = target==i\n",
    "        intersection = np.logical_and(prediction_c, target_c)\n",
    "        union = np.logical_or(prediction_c, target_c)\n",
    "        intou = np.sum(intersection)/np.sum(union)\n",
    "        mean.append(intou)\n",
    "        print(f\"{classnames[i]} iou:{intou}\")\n",
    "    mean = np.mean(mean)\n",
    "    print(f\"mIOU: {mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_state(model, optimizer, loss, test_loss, epoch):\n",
    "    model_path = f\"saved_models/unet_epoch_110+{epoch}.pt\"\n",
    "    state_dict = {\n",
    "        'epoch' : epoch,\n",
    "        'model_state_dict' : model.state_dict(),\n",
    "        'opt_state_dict' : optimizer.state_dict(),\n",
    "        'training_loss' : loss,\n",
    "        'test_loss' : test_loss,\n",
    "    }\n",
    "    torch.save(state_dict, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(model, trainloader, testloader, optimizer, criterion, epochs=50):\n",
    "    \n",
    "    checkpoint = len(trainloader)/3\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.\n",
    "        running_acc = 0.\n",
    "        epoch_loss = 0.\n",
    "        \n",
    "        start = time.time()\n",
    "        print(f\"-------------- Epoch: {epoch+1} Train --------------\")\n",
    "        for i, batch in enumerate(trainloader, 1):\n",
    "            \n",
    "\n",
    "            image, inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs) \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            running_loss += loss.item()\n",
    "            running_acc += (labels==predicted).sum().item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % checkpoint == 0: # print every 90 batches (90*16 images)\n",
    "                print(f\"Batch: {i+1}/{len(trainloader)}, loss: {(running_loss/checkpoint):.5f}, acc: {(100/(16*width*height)*running_acc/checkpoint):.5f}\")\n",
    "                running_loss = 0.\n",
    "                running_acc = 0.\n",
    "                \n",
    "                fig, ax = plt.subplots(1, 2, figsize=(20, 6))\n",
    "                img = image[0].cpu().data.numpy().reshape(height, width, 3)\n",
    "                label = labels[0].cpu().data.numpy().reshape(height, width)\n",
    "                preds = predicted[0].cpu().data.numpy().reshape(height, width)\n",
    "                concat_labels = np.concatenate([label, preds], axis=1)\n",
    "                ax[0].imshow(img.astype(np.uint8))\n",
    "                ax[1].imshow(concat_labels)\n",
    "                plt.show()\n",
    "                iou(preds, label)\n",
    "                \n",
    "        test_loss = evaluate_model(model, testloader, criterion)\n",
    "        epoch_loss /= len(trainloader)\n",
    "        # save every 10 epochs\n",
    "        if epoch % 10 == 9:\n",
    "            save_model_state(model, optimizer, epoch_loss, test_loss, epoch+1)\n",
    "            print(\"Saved model\")\n",
    "        print(f\"Epoch: {epoch+1} complete, time: {int(time.time()-start)}s, loss: {epoch_loss:.5f}\")\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Unet_model = Unet.Unet(input_channels=3, num_classes=8).to(device)\n",
    "optimizer = torch.optim.Adam(Unet_model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_net(Unet_model, trainloader, testloader, optimizer, loss_fn, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a trained model & setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Unet_model = Unet.Unet(input_channels=3, num_classes=8).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model_info = torch.load(\"saved_models/unet_epoch_140+70+200+110.pt\")\n",
    "optimizer = torch.optim.Adam(Unet_model.parameters())\n",
    "optimizer.load_state_dict(model_info[\"opt_state_dict\"])\n",
    "Unet_model.load_state_dict(model_info[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# start training again\n",
    "train_net(Unet_model, trainloader, testloader, optimizer, loss_fn, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the test data\n",
    "evaluate_model(Unet_model, testloader, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
